{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Librer√≠as ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator\n",
    "import os\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdefed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Configuraci√≥n del logger\n",
    "logger = logging.getLogger('preprocessor_logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s] - %(message)s'\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, df: pd.DataFrame, target_col: str = 'target'):\n",
    "        \"\"\"\n",
    "        Inicializa el preprocesador con el DataFrame original.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a procesar\n",
    "            target_col: Nombre de la columna target\n",
    "        \"\"\"\n",
    "        self.target_col = target_col\n",
    "        self.original_df = df.copy()\n",
    "        self.processed_df = None\n",
    "        self.cor_target = None\n",
    "        self.product_cols = None\n",
    "        \n",
    "        # Atributos para exportar\n",
    "        self.zones_ = None\n",
    "        self.zone_mapper_df = None\n",
    "        self.cols_to_drop_ = []\n",
    "        self.power_params_ = None\n",
    "        self.skewed_cols_ = []\n",
    "        self.high_corr_df_products = None\n",
    "        \n",
    "        logger.info(f\"Preprocessor inicializado - Shape original: {self.original_df.shape}\")\n",
    "\n",
    "    def _log_shape_change(self, previous_shape: tuple, operation: str):\n",
    "        \"\"\"Registra cambios en el shape del DataFrame.\"\"\"\n",
    "        current_shape = self.processed_df.shape\n",
    "        logger.info(\n",
    "            f\"{operation} - Shape cambiado de {previous_shape} a {current_shape} \"\n",
    "            f\"(Filas: {previous_shape[0]} ‚Üí {current_shape[0]}, \"\n",
    "            f\"Columnas: {previous_shape[1]} ‚Üí {current_shape[1]})\"\n",
    "        )\n",
    "\n",
    "    def group_sociodemographic_cols(self, sociodemographic_cols: list):\n",
    "        \"\"\"\n",
    "        Agrupa columnas sociodemogr√°ficas en una sola columna 'zone'.\n",
    "        \n",
    "        Args:\n",
    "            sociodemographic_cols: Lista de columnas sociodemogr√°ficas a agrupar\n",
    "        \"\"\"\n",
    "        logger.info(f\"Iniciando agrupaci√≥n de columnas sociodemogr√°ficas: {sociodemographic_cols}\")\n",
    "        \n",
    "        previous_shape = self.original_df.shape\n",
    "        \n",
    "        # Crear columna zone basada en agrupaci√≥n\n",
    "        self.original_df['zone'] = self.original_df.groupby(sociodemographic_cols).ngroup() + 1\n",
    "        \n",
    "        # Crear mapper de zonas\n",
    "        expanded_cols = sociodemographic_cols + ['zone']\n",
    "        self.zone_mapper_df = self.original_df[expanded_cols].drop_duplicates()\n",
    "        \n",
    "        self.zones_ = [str(col) for col in self.zone_mapper_df['zone'].unique()]\n",
    "        \n",
    "        # Eliminar columnas originales\n",
    "        self.original_df.drop(columns=sociodemographic_cols, inplace=True)\n",
    "        self.processed_df = self.original_df.copy()\n",
    "        \n",
    "        logger.info(f\"Agrupaci√≥n completada - {len(self.zone_mapper_df)} zonas √∫nicas creadas\")\n",
    "        self._log_shape_change(previous_shape, \"Agrupaci√≥n sociodemogr√°fica\")\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Elimina duplicados exactos del DataFrame.\"\"\"\n",
    "        logger.info(\"Iniciando eliminaci√≥n de duplicados exactos\")\n",
    "        \n",
    "        previous_shape = self.processed_df.shape\n",
    "        initial_rows = len(self.processed_df)\n",
    "        \n",
    "        self.processed_df = self.processed_df.drop_duplicates()\n",
    "        final_rows = len(self.processed_df)\n",
    "        removed_rows = initial_rows - final_rows\n",
    "        \n",
    "        logger.info(f\"Duplicados eliminados: {removed_rows} filas removidas\")\n",
    "        self._log_shape_change(previous_shape, \"Eliminaci√≥n de duplicados exactos\")\n",
    "\n",
    "    def handle_complex_duplicates(self):\n",
    "        \"\"\"\n",
    "        Maneja duplicados complejos donde las filas son id√©nticas excepto por el target.\n",
    "        Conserva la moda del target en casos de m√∫ltiples duplicados.\n",
    "        \"\"\"\n",
    "        logger.info(\"Iniciando manejo de duplicados complejos\")\n",
    "        \n",
    "        df = self.processed_df.copy()\n",
    "        previous_shape = df.shape\n",
    "        initial_rows = len(df)\n",
    "        \n",
    "        # Agrupar filas duplicadas excepto por target\n",
    "        columns = list(set(df.columns) - {self.target_col})\n",
    "        grupos_duplicados = df.groupby(columns).groups\n",
    "        \n",
    "        indices_a_eliminar = []\n",
    "        grupos_procesados = 0\n",
    "        \n",
    "        for fila, indices in grupos_duplicados.items():\n",
    "            if len(indices) > 1:  # Solo grupos con duplicados\n",
    "                grupos_procesados += 1\n",
    "                grupo_actual = df.loc[indices]\n",
    "                \n",
    "                if len(indices) == 2:\n",
    "                    # Eliminar todo el grupo (ambas filas)\n",
    "                    indices_a_eliminar.extend(indices)\n",
    "                else:\n",
    "                    # Grupos con m√°s de 2 filas: conservar solo la moda\n",
    "                    moda_target = grupo_actual[self.target_col].mode()\n",
    "                    \n",
    "                    if len(moda_target) > 0:\n",
    "                        moda = moda_target[0]\n",
    "                        # Conservar solo las filas con target = moda\n",
    "                        filas_a_eliminar = grupo_actual[grupo_actual[self.target_col] != moda].index\n",
    "                        indices_a_eliminar.extend(filas_a_eliminar)\n",
    "                    else:\n",
    "                        # Si no hay moda clara, eliminar todo el grupo\n",
    "                        indices_a_eliminar.extend(indices)\n",
    "        \n",
    "        # Crear nuevo DataFrame sin los duplicados problem√°ticos\n",
    "        self.processed_df = df.drop(indices_a_eliminar)\n",
    "        final_rows = len(self.processed_df)\n",
    "        removed_rows = initial_rows - final_rows\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Manejo de duplicados complejos completado - \"\n",
    "            f\"{grupos_procesados} grupos procesados, {removed_rows} filas eliminadas\"\n",
    "        )\n",
    "        self._log_shape_change(previous_shape, \"Manejo de duplicados complejos\")\n",
    "\n",
    "    def get_correlations(self):\n",
    "        \"\"\"Calcula correlaciones punto-biserial entre features y target.\"\"\"\n",
    "        logger.info(\"Calculando correlaciones con el target\")\n",
    "        \n",
    "        if self.target_col not in self.processed_df.columns:\n",
    "            raise ValueError(f\"Target column '{self.target_col}' no encontrada en el DataFrame\")\n",
    "        \n",
    "        cor_target = {}\n",
    "        features = [col for col in self.processed_df.columns if col != self.target_col]\n",
    "\n",
    "        for col in features:\n",
    "            corr, _ = pointbiserialr(self.processed_df[col], self.processed_df[self.target_col])\n",
    "            cor_target[col] = corr\n",
    "\n",
    "        self.cor_target = pd.Series(cor_target).sort_values(key=abs, ascending=False)\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Correlaciones calculadas - \"\n",
    "            f\"Rango: [{self.cor_target.min():.3f}, {self.cor_target.max():.3f}], \"\n",
    "            f\"Top 3: {self.cor_target.head(3).to_dict()}\"\n",
    "        )\n",
    "\n",
    "    def get_high_pair_correlations(self, product_cols: list):\n",
    "        \"\"\"\n",
    "        Identifica pares de variables con alta correlaci√≥n entre s√≠.\n",
    "        \n",
    "        Args:\n",
    "            product_cols: Lista de columnas de productos a analizar\n",
    "        \"\"\"\n",
    "        logger.info(f\"Buscando correlaciones altas entre {len(product_cols)} columnas de productos\")\n",
    "        \n",
    "        # Verificar que las columnas existen\n",
    "        missing_cols = set(product_cols) - set(self.processed_df.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Columnas no encontradas: {missing_cols}\")\n",
    "        \n",
    "        corr_abs_products = self.processed_df[product_cols].corr().abs()\n",
    "\n",
    "        high_corr_pairs_products = []\n",
    "        for i in range(len(corr_abs_products.columns)):\n",
    "            for j in range(i+1, len(corr_abs_products.columns)):\n",
    "                correlation = corr_abs_products.iloc[i, j]\n",
    "                if correlation > 0.7:\n",
    "                    high_corr_pairs_products.append({\n",
    "                        'var1': corr_abs_products.columns[i],\n",
    "                        'var2': corr_abs_products.columns[j], \n",
    "                        'correlation': correlation\n",
    "                    })\n",
    "\n",
    "        self.high_corr_df_products = pd.DataFrame(high_corr_pairs_products).sort_values(\n",
    "            'correlation', ascending=False\n",
    "        )\n",
    "        \n",
    "        # Filtrar correlaciones muy altas\n",
    "        high_corr_count = len(self.high_corr_df_products[self.high_corr_df_products['correlation'] > 0.95])\n",
    "        self.product_cols = product_cols\n",
    "        \n",
    "        logger.info(\n",
    "            f\"An√°lisis de correlaci√≥n completado - \"\n",
    "            f\"{len(high_corr_pairs_products)} pares con correlaci√≥n > 0.7, \"\n",
    "            f\"{high_corr_count} pares con correlaci√≥n > 0.95\"\n",
    "        )\n",
    "\n",
    "    def drop_high_correlated_cols(self):\n",
    "        \"\"\"Elimina columnas altamente correlacionadas, conservando las m√°s relevantes.\"\"\"\n",
    "        logger.info(\"Iniciando eliminaci√≥n de columnas altamente correlacionadas\")\n",
    "        \n",
    "        if self.high_corr_df_products is None:\n",
    "            raise ValueError(\"Debe ejecutar get_high_pair_correlations primero\")\n",
    "        \n",
    "        previous_shape = self.processed_df.shape\n",
    "        initial_cols = len(self.processed_df.columns)\n",
    "        \n",
    "        high_corr_filtered = self.high_corr_df_products[self.high_corr_df_products['correlation'] > 0.95]\n",
    "        \n",
    "        for _, row in high_corr_filtered.iterrows():\n",
    "            var1 = row['var1']\n",
    "            var2 = row['var2']\n",
    "\n",
    "            # Comparar la correlaci√≥n absoluta con el target\n",
    "            corr_var1 = abs(self.cor_target[var1])\n",
    "            corr_var2 = abs(self.cor_target[var2])\n",
    "\n",
    "            # Quedarse con la columna m√°s correlacionada, eliminar la otra\n",
    "            if corr_var1 < corr_var2:\n",
    "                col_to_drop = var1\n",
    "                col_to_keep = var2\n",
    "            else:\n",
    "                col_to_drop = var2\n",
    "                col_to_keep = var1\n",
    "            \n",
    "            if col_to_drop not in self.cols_to_drop_:\n",
    "                self.cols_to_drop_.append(col_to_drop)\n",
    "                logger.debug(f\"Marcada para eliminar: {col_to_drop} (corr: {corr_var1:.3f}) \"\n",
    "                           f\"vs {col_to_keep} (corr: {corr_var2:.3f})\")\n",
    "\n",
    "        self.cols_to_drop_ = list(set(self.cols_to_drop_))\n",
    "        self.product_cols = list(set(product_cols)-set(self.cols_to_drop_))\n",
    "        \n",
    "        # Eliminar columnas\n",
    "        columns_before_drop = set(self.processed_df.columns)\n",
    "        self.processed_df = self.processed_df.drop(columns=self.cols_to_drop_)\n",
    "        columns_after_drop = set(self.processed_df.columns)\n",
    "        dropped_columns = columns_before_drop - columns_after_drop\n",
    "        \n",
    "        final_cols = len(self.processed_df.columns)\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Eliminaci√≥n de columnas correlacionadas completada - \"\n",
    "            f\"{len(dropped_columns)} columnas eliminadas: {list(dropped_columns)}\"\n",
    "        )\n",
    "        self._log_shape_change(previous_shape, \"Eliminaci√≥n de columnas correlacionadas\")\n",
    "\n",
    "    def correct_skewness(self):\n",
    "        \"\"\"\n",
    "        Corrige asimetr√≠a en las columnas usando transformaci√≥n Yeo-Johnson.\n",
    "        \n",
    "        Args:\n",
    "            product_cols: Lista de columnas de productos a transformar\n",
    "        \"\"\"\n",
    "        logger.info(\"Iniciando correcci√≥n de asimetr√≠a\")\n",
    "        \n",
    "        # Calcular asimetr√≠a inicial\n",
    "        skewness_before = self.processed_df[self.product_cols].skew()\n",
    "        self.skewed_cols_ = skewness_before[abs(skewness_before) > 0.5].index.tolist()\n",
    "        \n",
    "        if not self.skewed_cols_:\n",
    "            logger.info(\"No se encontraron columnas con asimetr√≠a significativa (> 0.5)\")\n",
    "            return\n",
    "            \n",
    "        logger.info(f\"{len(self.skewed_cols_)} columnas con asimetr√≠a > 0.5: {self.skewed_cols_}\")\n",
    "        \n",
    "        # Aplicar transformaci√≥n Yeo-Johnson\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        self.processed_df[self.skewed_cols_] = pt.fit_transform(self.processed_df[self.skewed_cols_])\n",
    "        \n",
    "        # Calcular asimetr√≠a despu√©s de la transformaci√≥n\n",
    "        skewness_after = self.processed_df[self.skewed_cols_].skew()\n",
    "        \n",
    "        # Guardar par√°metros\n",
    "        if hasattr(pt, \"lambdas_\"):\n",
    "            self.power_params_ = dict(zip(self.skewed_cols_, pt.lambdas_))\n",
    "        else:\n",
    "            self.power_params_ = {}\n",
    "        \n",
    "        logger.info(\n",
    "            f\"Correcci√≥n de asimetr√≠a completada - \"\n",
    "            f\"Asimetr√≠a promedio: {skewness_before.mean():.3f} ‚Üí {skewness_after.mean():.3f}\"\n",
    "        )\n",
    "\n",
    "    def apply_one_hot(self):\n",
    "        \"\"\"Aplica one-hot encoding a la columna 'zone'.\"\"\"\n",
    "        logger.info(\"Aplicando one-hot encoding a la columna 'zone'\")\n",
    "        \n",
    "        if 'zone' not in self.processed_df.columns:\n",
    "            raise ValueError(\"Columna 'zone' no encontrada para one-hot encoding\")\n",
    "        \n",
    "        previous_shape = self.processed_df.shape\n",
    "        \n",
    "        # Convertir a entero y aplicar one-hot\n",
    "        self.processed_df['zone'] = self.processed_df['zone'].astype(int)\n",
    "        zone_dummies = pd.get_dummies(self.processed_df['zone'], prefix='zone')\n",
    "        \n",
    "        # Concatenar y eliminar columna original\n",
    "        self.processed_df = pd.concat([\n",
    "            self.processed_df.drop('zone', axis=1), \n",
    "            zone_dummies\n",
    "        ], axis=1)\n",
    "        \n",
    "        logger.info(f\"One-hot encoding completado - {len(zone_dummies.columns)} columnas zone creadas\")\n",
    "        self._log_shape_change(previous_shape, \"One-hot encoding\")\n",
    "\n",
    "    def apply_preprocess(self, sociodemographic_cols: list, product_cols: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Ejecuta el pipeline completo de preprocesamiento.\n",
    "        \n",
    "        Args:\n",
    "            sociodemographic_cols: Columnas sociodemogr√°ficas a agrupar\n",
    "            product_cols: Columnas de productos para an√°lisis de correlaci√≥n\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame procesado\n",
    "        \"\"\"\n",
    "        logger.info(\"=== INICIANDO PIPELINE COMPLETO DE PREPROCESAMIENTO ===\")\n",
    "        logger.info(f\"Columnas sociodemogr√°ficas: {sociodemographic_cols}\")\n",
    "        logger.info(f\"Columnas de productos: {product_cols}\")\n",
    "        \n",
    "        # Pipeline de procesamiento\n",
    "        self.group_sociodemographic_cols(sociodemographic_cols)\n",
    "        self.remove_duplicates()\n",
    "        self.handle_complex_duplicates()\n",
    "        self.get_correlations()\n",
    "        self.get_high_pair_correlations(product_cols)\n",
    "        self.drop_high_correlated_cols()\n",
    "        self.correct_skewness()\n",
    "        self.apply_one_hot()\n",
    "        \n",
    "        logger.info(\"=== PIPELINE COMPLETADO EXITOSAMENTE ===\")\n",
    "        logger.info(f\"Shape final del DataFrame: {self.processed_df.shape}\")\n",
    "        logger.info(f\"Columnas eliminadas: {len(self.cols_to_drop_)}\")\n",
    "        logger.info(f\"Columnas transformadas: {len(self.skewed_cols_)}\")\n",
    "        \n",
    "        return self.processed_df\n",
    "\n",
    "    def get_preprocessing_summary(self) -> dict:\n",
    "        \"\"\"Retorna un resumen del proceso de preprocesamiento.\"\"\"\n",
    "        return {\n",
    "            'original_shape': self.original_df.shape,\n",
    "            'processed_shape': self.processed_df.shape if self.processed_df is not None else None,\n",
    "            'zones_created': len(self.zone_mapper_df) if self.zone_mapper_df is not None else 0,\n",
    "            'columns_dropped': len(self.cols_to_drop_),\n",
    "            'columns_skewness_corrected': len(self.skewed_cols_),\n",
    "            'high_correlation_pairs': len(self.high_corr_df_products) if self.high_corr_df_products is not None else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d633b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/Documents/Master - TEC/9. MLOps/MNA_MLOps_Equipo12_backup\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../..\")  # subir al nivel ra√≠z del proyecto\n",
    "!pwd  # verificar ruta actual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7ebc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: dvc\r\n"
     ]
    }
   ],
   "source": [
    "!dvc pull data/raw/insurance_company_original.csv.dvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e884ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"notebooks\")\n",
    "\n",
    "\n",
    "file_name = '../data/raw/insurance_company_original.csv'\n",
    "sociodemographic_cols = [f\"SD_{i}\" for i in range(1, 44)]\n",
    "product_cols = [f\"PD_{i-44}\" for i in range(44, 86)]\n",
    "cols = sociodemographic_cols + product_cols + [\"target\"]\n",
    "df = pd.read_csv(file_name, header=None, names=cols)\n",
    "df = df.iloc[1:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806fa7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 19:11:17,176 - preprocessor_logger - INFO - [__init__] - Preprocessor inicializado - Shape original: (5821, 86)\n",
      "2025-11-12 19:11:17,177 - preprocessor_logger - INFO - [apply_preprocess] - === INICIANDO PIPELINE COMPLETO DE PREPROCESAMIENTO ===\n",
      "2025-11-12 19:11:17,177 - preprocessor_logger - INFO - [apply_preprocess] - Columnas sociodemogr√°ficas: ['SD_1', 'SD_2', 'SD_3', 'SD_4', 'SD_5', 'SD_6', 'SD_7', 'SD_8', 'SD_9', 'SD_10', 'SD_11', 'SD_12', 'SD_13', 'SD_14', 'SD_15', 'SD_16', 'SD_17', 'SD_18', 'SD_19', 'SD_20', 'SD_21', 'SD_22', 'SD_23', 'SD_24', 'SD_25', 'SD_26', 'SD_27', 'SD_28', 'SD_29', 'SD_30', 'SD_31', 'SD_32', 'SD_33', 'SD_34', 'SD_35', 'SD_36', 'SD_37', 'SD_38', 'SD_39', 'SD_40', 'SD_41', 'SD_42', 'SD_43']\n",
      "2025-11-12 19:11:17,177 - preprocessor_logger - INFO - [apply_preprocess] - Columnas de productos: ['PD_0', 'PD_1', 'PD_2', 'PD_3', 'PD_4', 'PD_5', 'PD_6', 'PD_7', 'PD_8', 'PD_9', 'PD_10', 'PD_11', 'PD_12', 'PD_13', 'PD_14', 'PD_15', 'PD_16', 'PD_17', 'PD_18', 'PD_19', 'PD_20', 'PD_21', 'PD_22', 'PD_23', 'PD_24', 'PD_25', 'PD_26', 'PD_27', 'PD_28', 'PD_29', 'PD_30', 'PD_31', 'PD_32', 'PD_33', 'PD_34', 'PD_35', 'PD_36', 'PD_37', 'PD_38', 'PD_39', 'PD_40', 'PD_41']\n",
      "2025-11-12 19:11:17,178 - preprocessor_logger - INFO - [group_sociodemographic_cols] - Iniciando agrupaci√≥n de columnas sociodemogr√°ficas: ['SD_1', 'SD_2', 'SD_3', 'SD_4', 'SD_5', 'SD_6', 'SD_7', 'SD_8', 'SD_9', 'SD_10', 'SD_11', 'SD_12', 'SD_13', 'SD_14', 'SD_15', 'SD_16', 'SD_17', 'SD_18', 'SD_19', 'SD_20', 'SD_21', 'SD_22', 'SD_23', 'SD_24', 'SD_25', 'SD_26', 'SD_27', 'SD_28', 'SD_29', 'SD_30', 'SD_31', 'SD_32', 'SD_33', 'SD_34', 'SD_35', 'SD_36', 'SD_37', 'SD_38', 'SD_39', 'SD_40', 'SD_41', 'SD_42', 'SD_43']\n",
      "2025-11-12 19:11:17,191 - preprocessor_logger - INFO - [group_sociodemographic_cols] - Agrupaci√≥n completada - 1734 zonas √∫nicas creadas\n",
      "2025-11-12 19:11:17,191 - preprocessor_logger - INFO - [_log_shape_change] - Agrupaci√≥n sociodemogr√°fica - Shape cambiado de (5821, 86) a (5821, 44) (Filas: 5821 ‚Üí 5821, Columnas: 86 ‚Üí 44)\n",
      "2025-11-12 19:11:17,191 - preprocessor_logger - INFO - [remove_duplicates] - Iniciando eliminaci√≥n de duplicados exactos\n",
      "2025-11-12 19:11:17,197 - preprocessor_logger - INFO - [remove_duplicates] - Duplicados eliminados: 602 filas removidas\n",
      "2025-11-12 19:11:17,197 - preprocessor_logger - INFO - [_log_shape_change] - Eliminaci√≥n de duplicados exactos - Shape cambiado de (5821, 44) a (5219, 44) (Filas: 5821 ‚Üí 5219, Columnas: 44 ‚Üí 44)\n",
      "2025-11-12 19:11:17,198 - preprocessor_logger - INFO - [handle_complex_duplicates] - Iniciando manejo de duplicados complejos\n",
      "2025-11-12 19:11:17,275 - preprocessor_logger - INFO - [handle_complex_duplicates] - Manejo de duplicados complejos completado - 49 grupos procesados, 98 filas eliminadas\n",
      "2025-11-12 19:11:17,275 - preprocessor_logger - INFO - [_log_shape_change] - Manejo de duplicados complejos - Shape cambiado de (5219, 44) a (5121, 44) (Filas: 5219 ‚Üí 5121, Columnas: 44 ‚Üí 44)\n",
      "2025-11-12 19:11:17,278 - preprocessor_logger - INFO - [get_correlations] - Calculando correlaciones con el target\n",
      "2025-11-12 19:11:17,300 - preprocessor_logger - INFO - [get_correlations] - Correlaciones calculadas - Rango: [-0.069, 0.158], Top 3: {'PD_3': 0.15832472625345365, 'PD_24': 0.15317100674423995, 'PD_38': 0.11645145380787937}\n",
      "2025-11-12 19:11:17,300 - preprocessor_logger - INFO - [get_high_pair_correlations] - Buscando correlaciones altas entre 42 columnas de productos\n",
      "2025-11-12 19:11:17,321 - preprocessor_logger - INFO - [get_high_pair_correlations] - An√°lisis de correlaci√≥n completado - 21 pares con correlaci√≥n > 0.7, 6 pares con correlaci√≥n > 0.95\n",
      "2025-11-12 19:11:17,321 - preprocessor_logger - INFO - [drop_high_correlated_cols] - Iniciando eliminaci√≥n de columnas altamente correlacionadas\n",
      "2025-11-12 19:11:17,323 - preprocessor_logger - INFO - [drop_high_correlated_cols] - Eliminaci√≥n de columnas correlacionadas completada - 6 columnas eliminadas: ['PD_23', 'PD_10', 'PD_28', 'PD_34', 'PD_21', 'PD_20']\n",
      "2025-11-12 19:11:17,323 - preprocessor_logger - INFO - [_log_shape_change] - Eliminaci√≥n de columnas correlacionadas - Shape cambiado de (5121, 44) a (5121, 38) (Filas: 5121 ‚Üí 5121, Columnas: 44 ‚Üí 38)\n",
      "2025-11-12 19:11:17,323 - preprocessor_logger - INFO - [correct_skewness] - Iniciando correcci√≥n de asimetr√≠a\n",
      "2025-11-12 19:11:17,326 - preprocessor_logger - INFO - [correct_skewness] - 33 columnas con asimetr√≠a > 0.5: ['PD_30', 'PD_6', 'PD_37', 'PD_13', 'PD_12', 'PD_35', 'PD_18', 'PD_32', 'PD_24', 'PD_36', 'PD_16', 'PD_14', 'PD_8', 'PD_9', 'PD_19', 'PD_31', 'PD_27', 'PD_4', 'PD_40', 'PD_1', 'PD_22', 'PD_11', 'PD_17', 'PD_7', 'PD_39', 'PD_2', 'PD_33', 'PD_26', 'PD_29', 'PD_41', 'PD_5', 'PD_25', 'PD_38']\n",
      "2025-11-12 19:11:17,396 - preprocessor_logger - INFO - [correct_skewness] - Correcci√≥n de asimetr√≠a completada - Asimetr√≠a promedio: 12.940 ‚Üí 11.366\n",
      "2025-11-12 19:11:17,397 - preprocessor_logger - INFO - [apply_one_hot] - Aplicando one-hot encoding a la columna 'zone'\n",
      "2025-11-12 19:11:17,419 - preprocessor_logger - INFO - [apply_one_hot] - One-hot encoding completado - 1733 columnas zone creadas\n",
      "2025-11-12 19:11:17,419 - preprocessor_logger - INFO - [_log_shape_change] - One-hot encoding - Shape cambiado de (5121, 38) a (5121, 1770) (Filas: 5121 ‚Üí 5121, Columnas: 38 ‚Üí 1770)\n",
      "2025-11-12 19:11:17,419 - preprocessor_logger - INFO - [apply_preprocess] - === PIPELINE COMPLETADO EXITOSAMENTE ===\n",
      "2025-11-12 19:11:17,420 - preprocessor_logger - INFO - [apply_preprocess] - Shape final del DataFrame: (5121, 1770)\n",
      "2025-11-12 19:11:17,420 - preprocessor_logger - INFO - [apply_preprocess] - Columnas eliminadas: 6\n",
      "2025-11-12 19:11:17,420 - preprocessor_logger - INFO - [apply_preprocess] - Columnas transformadas: 33\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(df)\n",
    "processed = preprocessor.apply_preprocess(sociodemographic_cols, product_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a215c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14cc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"\n",
    "X = processed.drop(columns=[target])\n",
    "y = processed[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Para la regresi√≥n logistica\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e303d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/480094317194489582', creation_time=1762995860178, experiment_id='480094317194489582', last_update_time=1762995860178, lifecycle_stage='active', name='MNA_MLOps_Model_Comparison', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuraci√≥n de MLFlow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"MNA_MLOps_Model_Comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d720ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LogisticRegression registrado en MLflow con m√©tricas:\n",
      "   accuracy: 0.9288\n",
      "   precision: 0.2000\n",
      "   recall: 0.0862\n",
      "   f1_score: 0.1205\n",
      "   roc_auc: 0.6732\n",
      "üèÉ View run LogisticRegression at: http://localhost:5000/#/experiments/480094317194489582/runs/7764519c9bfc4314ac9491120b73b55e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "‚úÖ RandomForest registrado en MLflow con m√©tricas:\n",
      "   accuracy: 0.9434\n",
      "   precision: 0.0000\n",
      "   recall: 0.0000\n",
      "   f1_score: 0.0000\n",
      "   roc_auc: 0.7500\n",
      "üèÉ View run RandomForest at: http://localhost:5000/#/experiments/480094317194489582/runs/3316f0864c244fa98d05dbe527541412\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [19:11:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost registrado en MLflow con m√©tricas:\n",
      "   accuracy: 0.9434\n",
      "   precision: 0.5000\n",
      "   recall: 0.0172\n",
      "   f1_score: 0.0333\n",
      "   roc_auc: 0.7498\n",
      "üèÉ View run XGBoost at: http://localhost:5000/#/experiments/480094317194489582/runs/f760884e03a54691a5b566e2555017b4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_and_log_model(model, model_name, X_train, X_test, y_train, y_test, params=None):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Registrar nombre del modelo como par√°metro y tag\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.set_tag(\"model_name\", model_name)\n",
    "        \n",
    "        mlflow.log_param(\"base_model\", model_name)\n",
    "        mlflow.log_param(\"model_id\", model_name + \"_individual\")\n",
    "        \n",
    "        \n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        \n",
    "        # Entrenamiento\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        # M√©tricas\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "            \"f1_score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        }\n",
    "        if y_proba is not None:\n",
    "            metrics[\"roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "            \n",
    "        cm_normalized = confusion_matrix(y_test, y_pred)\n",
    "        labels = sorted(list(set(y_test)))\n",
    "\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                    xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.title(f\"Matriz de Confusi√≥n - {model_name}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Guardar imagen localmente\n",
    "        os.makedirs(\"./reports/confusion_matrices\", exist_ok=True)\n",
    "        cm_path = f\"./reports/confusion_matrices/confusion_matrix_{model_name}.png\"\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Registrar en MLflow\n",
    "        mlflow.log_artifact(cm_path)\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log del modelo\n",
    "        # mlflow.sklearn.log_model(model, name=f\"model_{model_name}\")\n",
    "\n",
    "        print(f\"‚úÖ {model_name} registrado en MLflow con m√©tricas:\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"   {k}: {v:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Entrenamiento de modelos\n",
    "# ============================================\n",
    "\n",
    "# --- Regresi√≥n Log√≠stica ---\n",
    "log_reg_params = {\"solver\": \"liblinear\", \"random_state\": 42}\n",
    "log_reg = LogisticRegression(**log_reg_params)\n",
    "train_and_log_model(log_reg, \"LogisticRegression\", X_train_scaled, X_test_scaled, y_train, y_test, log_reg_params)\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_params = {\"n_estimators\": 200, \"max_depth\": 10, \"random_state\": 42}\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "train_and_log_model(rf, \"RandomForest\", X_train, X_test, y_train, y_test, rf_params)\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "    \"use_label_encoder\": False,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "train_and_log_model(xgb, \"XGBoost\", X_train, X_test, y_train, y_test, xgb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ed37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Union, Optional, Dict, Any\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger('preprocessor_logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "class H2OAutoMLTrainer:\n",
    "    def __init__(self, max_models: int = 20, max_runtime_secs: int = 300,\n",
    "                 seed: int = 42, balance_classes: bool = True,\n",
    "                 stopping_metric: str = \"AUC\"):\n",
    "        \"\"\"\n",
    "        Inicializa el entrenador de H2O AutoML.\n",
    "\n",
    "        Args:\n",
    "            max_models: N√∫mero m√°ximo de modelos a entrenar\n",
    "            max_runtime_secs: Tiempo m√°ximo de ejecuci√≥n en segundos\n",
    "            seed: Semilla para reproducibilidad\n",
    "            balance_classes: Balancear clases para datos desbalanceados\n",
    "            stopping_metric: M√©trica para early stopping\n",
    "        \"\"\"\n",
    "        self.max_models = max_models\n",
    "        self.max_runtime_secs = max_runtime_secs\n",
    "        self.seed = seed\n",
    "        self.balance_classes = balance_classes\n",
    "        self.stopping_metric = stopping_metric\n",
    "\n",
    "        # Atributos del modelo\n",
    "        self.aml = None\n",
    "        self.leader = None\n",
    "        self.leaderboard = None\n",
    "        self.h2o_frame = None\n",
    "\n",
    "        # Estado de H2O\n",
    "        self.h2o_initialized = False\n",
    "\n",
    "        logger.info(f\"H2OAutoMLTrainer inicializado - max_models: {max_models}, \"\n",
    "                    f\"max_runtime_secs: {max_runtime_secs}\")\n",
    "\n",
    "    def initialize_h2o(self) -> None:\n",
    "        \"\"\"Inicializa la conexi√≥n con H2O.\"\"\"\n",
    "        if not self.h2o_initialized:\n",
    "            try:\n",
    "                h2o.init()\n",
    "                self.h2o_initialized = True\n",
    "                logger.info(\"H2O inicializado exitosamente\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error inicializando H2O: {e}\")\n",
    "                raise\n",
    "\n",
    "    def prepare_data(self, df: pd.DataFrame, target_col: str = 'target') -> None:\n",
    "        \"\"\"\n",
    "        Prepara los datos para H2O AutoML.\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame con los datos\n",
    "            target_col: Nombre de la columna target\n",
    "        \"\"\"\n",
    "        logger.info(f\"Preparando datos - Shape: {df.shape}, Target: {target_col}\")\n",
    "\n",
    "        if not self.h2o_initialized:\n",
    "            self.initialize_h2o()\n",
    "\n",
    "        # Convertir a H2OFrame\n",
    "        self.h2o_frame = h2o.H2OFrame(df)\n",
    "\n",
    "        # Convertir target a factor (para clasificaci√≥n)\n",
    "        if target_col in self.h2o_frame.columns:\n",
    "            self.h2o_frame[target_col] = self.h2o_frame[target_col].asfactor()\n",
    "            logger.info(f\"Target '{target_col}' convertido a factor\")\n",
    "\n",
    "        logger.info(f\"Datos preparados - H2OFrame shape: {self.h2o_frame.shape}\")\n",
    "\n",
    "    def train(self, target_col: str = 'target',\n",
    "              training_frame: Optional[h2o.H2OFrame] = None) -> None:\n",
    "        \"\"\"\n",
    "        Entrena el modelo AutoML.\n",
    "\n",
    "        Args:\n",
    "            target_col: Columna target\n",
    "            training_frame: Frame de entrenamiento (opcional, usa self.h2o_frame por defecto)\n",
    "        \"\"\"\n",
    "        logger.info(\"Iniciando entrenamiento AutoML\")\n",
    "\n",
    "        if training_frame is None:\n",
    "            if self.h2o_frame is None:\n",
    "                raise ValueError(\"No hay datos preparados. Ejecute prepare_data primero.\")\n",
    "            training_frame = self.h2o_frame\n",
    "\n",
    "        # Configurar AutoML\n",
    "        self.aml = H2OAutoML(\n",
    "            max_models=self.max_models,\n",
    "            seed=self.seed,\n",
    "            max_runtime_secs=self.max_runtime_secs,\n",
    "            balance_classes=self.balance_classes,\n",
    "            stopping_metric=self.stopping_metric\n",
    "        )\n",
    "\n",
    "        # Entrenar\n",
    "        self.aml.train(y=target_col, training_frame=training_frame)\n",
    "\n",
    "        # Obtener resultados\n",
    "        self.leader = self.aml.leader\n",
    "        self.leaderboard = self.aml.leaderboard\n",
    "\n",
    "        logger.info(\"Entrenamiento AutoML completado exitosamente\")\n",
    "        self._log_training_summary()\n",
    "\n",
    "    def _log_training_summary(self) -> None:\n",
    "        \"\"\"Registra un resumen del entrenamiento.\"\"\"\n",
    "        if self.leaderboard is not None:\n",
    "            lb_head = self.leaderboard.head()\n",
    "            logger.info(\"Leaderboard - Top modelos:\")\n",
    "            for i, (model_id, *metrics) in enumerate(lb_head.as_data_frame().itertuples(index=False)):\n",
    "                logger.info(f\"  {i + 1}. {model_id} - {metrics}\")\n",
    "\n",
    "        if self.leader is not None:\n",
    "            logger.info(f\"Modelo l√≠der: {self.leader.model_id}\")\n",
    "\n",
    "    def predict(self, X_data: Union[pd.DataFrame, h2o.H2OFrame],\n",
    "                best_threshold: Optional[float] = None,\n",
    "                auto_threshold: bool = False,\n",
    "                y_true: Optional[np.ndarray] = None,\n",
    "                return_h2o_frame: bool = False) -> Union[pd.DataFrame, h2o.H2OFrame]:\n",
    "        \"\"\"\n",
    "        Realiza predicciones con el modelo l√≠der.\n",
    "\n",
    "        Args:\n",
    "            X_data: Datos para predecir\n",
    "            best_threshold: Umbral √≥ptimo para clasificaci√≥n (opcional)\n",
    "            auto_threshold: Si calcular autom√°ticamente el threshold que maximiza AUC\n",
    "            y_true: Valores reales (requerido si auto_threshold=True)\n",
    "            return_h2o_frame: Si retornar H2OFrame en lugar de DataFrame\n",
    "\n",
    "        Returns:\n",
    "            DataFrame o H2OFrame con predicciones\n",
    "        \"\"\"\n",
    "        logger.info(\"Realizando predicciones\")\n",
    "\n",
    "        if self.leader is None:\n",
    "            raise ValueError(\"No hay modelo entrenado. Ejecute train primero.\")\n",
    "\n",
    "        # Validar par√°metros para auto_threshold\n",
    "        if auto_threshold and y_true is None:\n",
    "            raise ValueError(\"y_true es requerido cuando auto_threshold=True\")\n",
    "\n",
    "        # Convertir a H2OFrame si es necesario\n",
    "        if isinstance(X_data, pd.DataFrame):\n",
    "            h2o_X = h2o.H2OFrame(X_data)\n",
    "            logger.info(f\"DataFrame convertido a H2OFrame - Shape: {h2o_X.shape}\")\n",
    "        else:\n",
    "            h2o_X = X_data\n",
    "\n",
    "        # Realizar predicciones\n",
    "        predictions = self.leader.predict(h2o_X)\n",
    "\n",
    "        if return_h2o_frame:\n",
    "            # Combinar features con predicciones\n",
    "            results_h2o = h2o_X.cbind(predictions)\n",
    "            logger.info(\"Predicciones completadas - Retornando H2OFrame\")\n",
    "            return results_h2o\n",
    "        else:\n",
    "            # Convertir a DataFrame de pandas\n",
    "            features_df = h2o_X.as_data_frame().copy()\n",
    "            probabilities = predictions['p1'].as_data_frame().values.flatten()\n",
    "            predicted_classes = predictions['predict'].as_data_frame().values.flatten()\n",
    "\n",
    "            results_df = features_df.copy()\n",
    "            results_df['predicted_prob'] = probabilities\n",
    "            results_df['predicted_class'] = predicted_classes\n",
    "\n",
    "            # Calcular threshold autom√°ticamente si se solicita\n",
    "            if auto_threshold:\n",
    "                # Calcular curva ROC\n",
    "                fpr, tpr, thresholds = roc_curve(y_true, probabilities)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                # Encontrar threshold que maximiza AUC (punto m√°s alejado de la diagonal)\n",
    "                optimal_idx = np.argmax(tpr - fpr)\n",
    "                best_threshold = thresholds[optimal_idx]\n",
    "\n",
    "                logger.info(f\"Threshold autom√°tico calculado: {best_threshold:.4f} (AUC: {roc_auc:.4f})\")\n",
    "\n",
    "            # Aplicar threshold si se proporciona o se calcula autom√°ticamente\n",
    "            if best_threshold is not None:\n",
    "                logger.info(f\"Umbral aplicado: {best_threshold}\")\n",
    "\n",
    "                results_df['prediction'] = ((results_df['predicted_prob'] >= best_threshold) &\n",
    "                                            (results_df['predicted_class'] == 1)).astype(int)\n",
    "            else:\n",
    "                # Si no hay threshold, usar predicted_class directamente\n",
    "                results_df['prediction'] = results_df['predicted_class']\n",
    "\n",
    "            logger.info(f\"Predicciones completadas - DataFrame shape: {results_df.shape}\")\n",
    "            return results_df\n",
    "\n",
    "    def predict_with_actuals(self, X_data: Union[pd.DataFrame, h2o.H2OFrame],\n",
    "                             y_actual: pd.Series,\n",
    "                             best_threshold: Optional[float] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Realiza predicciones e incluye los valores reales.\n",
    "\n",
    "        Args:\n",
    "            X_data: Features para predecir\n",
    "            y_actual: Valores reales del target\n",
    "            best_threshold: Umbral √≥ptimo para clasificaci√≥n\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con predicciones y valores reales\n",
    "        \"\"\"\n",
    "        logger.info(\"Realizando predicciones con valores reales\")\n",
    "\n",
    "        # Obtener predicciones base\n",
    "        results_df = self.predict(X_data, best_threshold=best_threshold)\n",
    "\n",
    "        # Agregar valores reales\n",
    "        results_df['actual'] = y_actual.values\n",
    "\n",
    "        logger.info(f\"Predicciones con valores reales completadas - Shape: {results_df.shape}\")\n",
    "        return results_df\n",
    "\n",
    "    def get_model_performance(self, test_data: Optional[h2o.H2OFrame] = None,\n",
    "                              target_col: str = 'target') -> Any:\n",
    "        \"\"\"\n",
    "        Eval√∫a el performance del modelo l√≠der.\n",
    "\n",
    "        Args:\n",
    "            test_data: Datos de test (opcional)\n",
    "            target_col: Columna target\n",
    "\n",
    "        Returns:\n",
    "            Objeto de performance del modelo\n",
    "        \"\"\"\n",
    "        logger.info(\"Evaluando performance del modelo\")\n",
    "\n",
    "        if self.leader is None:\n",
    "            raise ValueError(\"No hay modelo entrenado. Ejecute train primero.\")\n",
    "\n",
    "        if test_data is None:\n",
    "            if self.h2o_frame is None:\n",
    "                raise ValueError(\"No hay datos disponibles para evaluaci√≥n\")\n",
    "            test_data = self.h2o_frame\n",
    "\n",
    "        performance = self.leader.model_performance(test_data=test_data)\n",
    "\n",
    "        # Log de m√©tricas principales\n",
    "        if hasattr(performance, 'auc'):\n",
    "            logger.info(f\"AUC: {performance.auc():.4f}\")\n",
    "\n",
    "        if hasattr(performance, 'logloss'):\n",
    "            logger.info(f\"LogLoss: {performance.logloss():.4f}\")\n",
    "        \n",
    "        if hasattr(performance, 'accuracy'):\n",
    "            acc_list = performance.accuracy()\n",
    "            if isinstance(acc_list, list) and len(acc_list) > 0:\n",
    "                acc_value = acc_list[0][1]\n",
    "                logger.info(f\"Accuracy: {acc_value:.4f}\")\n",
    "            else:\n",
    "                logger.info(\"Accuracy: N/A\")\n",
    "        \n",
    "                return performance\n",
    "\n",
    "    def get_leaderboard(self, as_dataframe: bool = True) -> Union[h2o.H2OFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Obtiene el leaderboard de modelos.\n",
    "\n",
    "        Args:\n",
    "            as_dataframe: Si retornar como DataFrame de pandas\n",
    "\n",
    "        Returns:\n",
    "            Leaderboard de modelos\n",
    "        \"\"\"\n",
    "        if self.leaderboard is None:\n",
    "            raise ValueError(\"No hay leaderboard disponible. Ejecute train primero.\")\n",
    "\n",
    "        if as_dataframe:\n",
    "            return self.leaderboard.as_data_frame()\n",
    "        else:\n",
    "            return self.leaderboard\n",
    "\n",
    "    def save_model(self, model_name: str = \"h2o_automl_model\", base_path: str = \"./\") -> str:\n",
    "        \"\"\"\n",
    "        Guarda el modelo en disco con nombre configurable.\n",
    "\n",
    "        Args:\n",
    "            model_name: Nombre del modelo (sin extensi√≥n)\n",
    "            base_path: Ruta base donde guardar el modelo\n",
    "\n",
    "        Returns:\n",
    "            Ruta completa donde se guard√≥ el modelo\n",
    "        \"\"\"\n",
    "        if self.leader is None:\n",
    "            raise ValueError(\"No hay modelo l√≠der para guardar\")\n",
    "\n",
    "        # Crear directorio si no existe\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "        # Guardar modelo\n",
    "        model_path = h2o.save_model(\n",
    "            model=self.leader,\n",
    "            path=base_path,\n",
    "            force=True,\n",
    "            filename=model_name\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Modelo guardado en: {model_path}\")\n",
    "\n",
    "    def shutdown_h2o(self) -> None:\n",
    "        \"\"\"Cierra la conexi√≥n con H2O.\"\"\"\n",
    "        if self.h2o_initialized:\n",
    "            h2o.cluster().shutdown()\n",
    "            self.h2o_initialized = False\n",
    "            logger.info(\"H2O shutdown completado\")\n",
    "\n",
    "    def get_training_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Retorna un resumen del entrenamiento.\n",
    "\n",
    "        Returns:\n",
    "            Diccionario con informaci√≥n del entrenamiento\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            'max_models': self.max_models,\n",
    "            'max_runtime_secs': self.max_runtime_secs,\n",
    "            'seed': self.seed,\n",
    "            'balance_classes': self.balance_classes,\n",
    "            'stopping_metric': self.stopping_metric,\n",
    "            'leader_model': self.leader.model_id if self.leader else None,\n",
    "            'models_trained': len(self.leaderboard) if self.leaderboard else 0,\n",
    "            'h2o_initialized': self.h2o_initialized\n",
    "        }\n",
    "\n",
    "        if self.leaderboard is not None and len(self.leaderboard) > 0:\n",
    "            lb_df = self.leaderboard.as_data_frame()\n",
    "            summary['top_model_auc'] = lb_df.iloc[0]['auc'] if 'auc' in lb_df.columns else None\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Support for context manager.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Cleanup on context manager exit.\"\"\"\n",
    "        self.shutdown_h2o()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0fd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def plot_interactive_roc(y_true, y_score, model_name=\"Model\"):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Crear traza principal de la curva ROC\n",
    "    trace_main = go.Scatter(\n",
    "        x=fpr, \n",
    "        y=tpr,\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='orange', width=2),\n",
    "        hovertemplate=(\n",
    "            \"<b>Threshold:</b> %{customdata[0]:.3f}<br>\"\n",
    "            \"<b>TPR (Recall):</b> %{y:.3f}<br>\"\n",
    "            \"<b>FPR:</b> %{x:.3f}<br>\"\n",
    "        ),\n",
    "        name=f\"ROC (AUC = {roc_auc:.3f})\",\n",
    "        customdata=np.stack((thresholds,), axis=-1)\n",
    "    )\n",
    "\n",
    "    # L√≠nea diagonal (clasificador aleatorio)\n",
    "    trace_ref = go.Scatter(\n",
    "        x=[0, 1], y=[0, 1],\n",
    "        mode='lines',\n",
    "        line=dict(color='navy', dash='dash'),\n",
    "        showlegend=True,\n",
    "        name='Random Classifier'\n",
    "    )\n",
    "\n",
    "    # Crear figura\n",
    "    fig = go.Figure(data=[trace_main, trace_ref])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Interactive ROC Curve - {model_name}\",\n",
    "        xaxis_title=\"False Positive Rate (FPR)\",\n",
    "        yaxis_title=\"True Positive Rate (TPR)\",\n",
    "        template=\"plotly_white\",\n",
    "        width=800, height=600,\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(x=0.65, y=0.1, bgcolor='rgba(255,255,255,0.7)')\n",
    "    )\n",
    "    \n",
    "    os.makedirs(\"./visualization/roc_curves\", exist_ok=True)\n",
    "    roc_path = f\"./visualization/roc_curves/cm_{model_name}.html\"\n",
    "\n",
    "    fig.write_html(roc_path)\n",
    "    mlflow.log_artifact(roc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0679c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:H2OAutoMLTrainer inicializado - max_models: 20, max_runtime_secs: 300\n",
      "INFO:__main__:Preparando datos - Shape: (5121, 1770), Target: target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"23.0.2\" 2025-01-21; OpenJDK Runtime Environment Homebrew (build 23.0.2); OpenJDK 64-Bit Server VM Homebrew (build 23.0.2, mixed mode, sharing)\n",
      "  Starting server from /Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/v4/2y3d_dfd7hv8b31yqy3186v40000gp/T/tmp0eo61_hv\n",
      "  JVM stdout: /var/folders/v4/2y3d_dfd7hv8b31yqy3186v40000gp/T/tmp0eo61_hv/h2o_luis_caporal_started_from_python.out\n",
      "  JVM stderr: /var/folders/v4/2y3d_dfd7hv8b31yqy3186v40000gp/T/tmp0eo61_hv/h2o_luis_caporal_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Mexico_City</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.8</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 4 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_luis_caporal_b1tb7z</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.979 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       America/Mexico_City\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.8\n",
       "H2O_cluster_version_age:    1 month and 4 days\n",
       "H2O_cluster_name:           H2O_from_python_luis_caporal_b1tb7z\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.979 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.12 final\n",
       "--------------------------  -----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:H2O inicializado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Target 'target' convertido a factor\n",
      "INFO:__main__:Datos preparados - H2OFrame shape: (5121, 1770)\n",
      "INFO:__main__:Iniciando entrenamiento AutoML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "19:11:38.358: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà‚ñà\n",
      "19:11:43.791: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:11:47.696: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà\n",
      "19:11:59.647: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:12:01.952: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:12:08.496: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà\n",
      "19:12:11.302: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "\n",
      "19:12:14.113: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:12:17.141: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà\n",
      "19:12:19.35: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:12:21.31: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà‚ñà\n",
      "19:12:23.342: _train param, Dropping bad and constant columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "19:14:45.943: _train param, Dropping unused columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà\n",
      "19:14:48.24: _train param, Dropping unused columns: [zone_1066, zone_1068, zone_440, zone_1620, zone_560, zone_1500, zone_674, zone_559, zone_558, zone_679, zone_1062, zone_1063, zone_1, zone_1515, zone_1638, zone_1078, zone_1199, zone_211, zone_574, zone_452, zone_446, zone_567, zone_687, zone_322, zone_1071, zone_449, zone_689, zone_1600, zone_1601, zone_1722, zone_1727, zone_1042, zone_222, zone_100, zone_221, zone_584, zone_583, zone_577, zone_575, zone_338, zone_337, zone_1612, zone_1733, zone_1616, zone_350, zone_471, zone_591, zone_595, zone_594, zone_589, zone_104, zone_467, zone_588, zone_1290, zone_109, zone_900, zone_1172, zone_909, zone_907, zone_1703, zone_1020, zone_1384, zone_1143, zone_640, zone_882, zone_30, zone_633, zone_874, zone_873, zone_994, zone_637, zone_997, zone_518, zone_517, zone_1716, zone_1274, zone_44, zone_1156, zone_1279, zone_890, zone_886, zone_401, zone_642, zone_883, zone_648, zone_526, zone_647, zone_767, zone_524, zone_408, zone_649, zone_1248, zone_1008, zone_18, zone_16, zone_1000, zone_1121, zone_1122, zone_1243, zone_662, zone_540, zone_782, zone_1124, zone_781, zone_1488, zone_534, zone_655, zone_653, zone_774, zone_895, zone_658, zone_656, zone_1360, zone_1259, zone_790, zone_1010, zone_1252, zone_1011, zone_1496, zone_22, zone_431, zone_430, zone_551, zone_1014, zone_1256, zone_1498, zone_792, zone_1499, zone_1137, zone_303, zone_424, zone_545, zone_544, zone_669, zone_668, zone_1491, zone_546, zone_1250, zone_1226, zone_1227, zone_1228, zone_1349, zone_1229, zone_1221, zone_1584, zone_1344, zone_164, zone_1104, zone_72, zone_833, zone_717, zone_715, zone_1237, zone_1359, zone_1239, zone_170, zone_290, zone_295, zone_1230, zone_1472, zone_1110, zone_1352, zone_89, zone_171, zone_1111, zone_88, zone_299, zone_970, zone_168, zone_604, zone_844, zone_1470, zone_607, zone_968, zone_1567, zone_1448, zone_58, zone_183, zone_1320, zone_1442, zone_51, zone_610, zone_972, zone_179, zone_615, zone_856, zone_854, zone_859, zone_1336, zone_191, zone_69, zone_1571, zone_1572, zone_1331, zone_1695, zone_1455, zone_1456, zone_622, zone_985, zone_747, zone_988, zone_866, zone_987, zone_865, zone_1690, zone_1424, zone_1307, zone_1308, zone_480, zone_486, zone_1420, zone_122, zone_1300, zone_1663, zone_1422, zone_241, zone_362, zone_237, zone_479, zone_113, zone_919, zone_918, zone_917, zone_1435, zone_1318, zone_493, zone_491, zone_1551, zone_1310, zone_1673, zone_254, zone_496, zone_1553, zone_923, zone_922, zone_800, zone_928, zone_1406, zone_1528, zone_141, zone_140, zone_261, zone_1642, zone_142, zone_1643, zone_95, zone_259, zone_257, zone_499, zone_256, zone_498, zone_1082, zone_812, zone_810, zone_816, zone_1414, zone_1539, zone_150, zone_392, zone_391, zone_153, zone_395, zone_1412, zone_941, zone_388, zone_1092, zone_823, zone_1094, zone_828, zone_949, zone_948, zone_705]\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Entrenamiento AutoML completado exitosamente\n",
      "INFO:__main__:Leaderboard - Top modelos:\n",
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "INFO:__main__:  1. StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136 - [0.8124427830332621, 0.1892722856821518, 0.2689349365906862, 0.3753433018004272, 0.2249359519717992, 0.0505961824894595]\n",
      "INFO:__main__:  2. StackedEnsemble_AllModels_1_AutoML_1_20251112_191136 - [0.8100015257857798, 0.1908659580055194, 0.2751318854290092, 0.3603143118706134, 0.226331436375112, 0.0512259190916214]\n",
      "INFO:__main__:  3. GBM_1_AutoML_1_20251112_191136 - [0.8067973756484589, 0.1940447780083969, 0.2163126517039348, 0.3446368629844369, 0.2275361231030927, 0.0517726873167857]\n",
      "INFO:__main__:  4. XGBoost_1_AutoML_1_20251112_191136 - [0.8043942630454685, 0.5397874427693786, 0.2543667701638603, 0.3112602990540128, 0.4331105107301356, 0.1875847145049188]\n",
      "INFO:__main__:  5. GBM_grid_1_AutoML_1_20251112_191136_model_2 - [0.7938281965212085, 0.2010465251416762, 0.2753786327586598, 0.3808742752517546, 0.2299326964458265, 0.0528690448948486]\n",
      "INFO:__main__:  6. XGBoost_grid_1_AutoML_1_20251112_191136_model_2 - [0.7909673481843149, 0.1938585138126121, 0.2346695798434954, 0.3574534635337199, 0.2279955678664031, 0.0519819789667236]\n",
      "INFO:__main__:  7. DRF_1_AutoML_1_20251112_191136 - [0.7907003356728715, 0.2035507611551102, 0.2338654001413844, 0.3841928593225511, 0.2322743862961732, 0.0539513905292638]\n",
      "INFO:__main__:  8. GBM_2_AutoML_1_20251112_191136 - [0.79047146780592, 0.1976588094070944, 0.22405371144403, 0.2609093683246872, 0.2301431815182679, 0.0529658839993504]\n",
      "INFO:__main__:  9. GBM_grid_1_AutoML_1_20251112_191136_model_1 - [0.7886023802258163, 0.1976235844779884, 0.1808835823389118, 0.2748321635642355, 0.2301604846807136, 0.052973848708461]\n",
      "INFO:__main__:  10. GBM_5_AutoML_1_20251112_191136 - [0.7881064998474214, 0.1974795533274215, 0.2068087595447574, 0.2598031736344217, 0.2303798326376033, 0.0530748672861301]\n",
      "INFO:__main__:Modelo l√≠der: StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136\n",
      "INFO:__main__:Registrando m√©tricas individuales de cada modelo del leaderboard...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "stackedensemble prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/cc5439a05d54491e9c7f2f4061914974\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "stackedensemble prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo StackedEnsemble_AllModels_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo StackedEnsemble_AllModels_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_StackedEnsemble_AllModels_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/5a8e85beef3a4f798a5c6af6901a78c7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_GBM_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/b3d96e0bee434e9192275a1bfdd25863\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XGBoost_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XGBoost_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/6a41fdee1e64492587a14cbda8cacaf2\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_grid_1_AutoML_1_20251112_191136_model_2 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_grid_1_AutoML_1_20251112_191136_model_2 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_GBM_grid_1_AutoML_1_20251112_191136_model_2 at: http://localhost:5000/#/experiments/480094317194489582/runs/37eef883ac4847d28c02bd3252b321aa\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_2 registrado: \n",
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_2 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_XGBoost_grid_1_AutoML_1_20251112_191136_model_2 at: http://localhost:5000/#/experiments/480094317194489582/runs/b8bf991792a64d9cb3b36f22d0cabf35\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "drf prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo DRF_1_AutoML_1_20251112_191136 registrado: \n",
      "INFO:__main__:‚úÖ Modelo DRF_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_DRF_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/af19378f6a734bee9352d6ed86710a69\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_2_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_GBM_2_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/ea04064ebd3a43e0bf96fcd34874b72c\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_2_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_GBM_grid_1_AutoML_1_20251112_191136_model_1 at: http://localhost:5000/#/experiments/480094317194489582/runs/484626c34c624eb4b0006cdd01f6d686\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_5_AutoML_1_20251112_191136 registrado: \n",
      "INFO:__main__:‚úÖ Modelo GBM_5_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_GBM_5_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/b2e88472d8d84da5ae95dbf44735ba6d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_4_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_4_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_GBM_4_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/e2184cead32e4adf98944368190f108d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "gbm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GBM_3_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GBM_3_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_GBM_3_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/7b55339b36734e9da5ddaf76c59e65ca\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_3_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XGBoost_3_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XGBoost_3_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/68bdfd45a69648db9e08c2d03cc10891\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_2_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XGBoost_2_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XGBoost_2_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/00552a8d8f214322ba0b39d1a7e10b2f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XGBoost_grid_1_AutoML_1_20251112_191136_model_1 at: http://localhost:5000/#/experiments/480094317194489582/runs/41d6d2ea45554420801b8a760aded873\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "xgboost prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_3 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XGBoost_grid_1_AutoML_1_20251112_191136_model_3 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XGBoost_grid_1_AutoML_1_20251112_191136_model_3 at: http://localhost:5000/#/experiments/480094317194489582/runs/cdc95cab2ef042bcb618fceaff23d507\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "drf prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo XRT_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo XRT_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_XRT_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/e19c527aeee9472fa325a77641755977\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "glm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo GLM_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo GLM_1_AutoML_1_20251112_191136 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_GLM_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/229698cc43004cedb3ec1a1ec297708b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "deeplearning prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_3_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_3_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run H2O_Model_DeepLearning_grid_3_AutoML_1_20251112_191136_model_1 at: http://localhost:5000/#/experiments/480094317194489582/runs/5e2853f1296b4a1cacf0d38b652f1be8\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "deeplearning prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_2_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_DeepLearning_grid_2_AutoML_1_20251112_191136_model_1 at: http://localhost:5000/#/experiments/480094317194489582/runs/eeb242dbac4547f0ab5e15e9761d6dce\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_2_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "deeplearning prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_DeepLearning_grid_1_AutoML_1_20251112_191136_model_1 at: http://localhost:5000/#/experiments/480094317194489582/runs/fdccf34059a24dc4af7a9e6e3fc9a79f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Modelo DeepLearning_grid_1_AutoML_1_20251112_191136_model_1 registrado: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "deeplearning prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis.caporal/miniconda3/envs/notebooks/lib/python3.11/site-packages/h2o/frame.py:1983: H2ODependencyWarning:\n",
      "\n",
      "Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "\n",
      "INFO:__main__:‚úÖ Modelo DeepLearning_1_AutoML_1_20251112_191136 registrado: \n",
      "INFO:__main__:‚úÖ Modelo DeepLearning_1_AutoML_1_20251112_191136 registrado: \n",
      "INFO:__main__:Evaluando performance del modelo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "üèÉ View run H2O_Model_DeepLearning_1_AutoML_1_20251112_191136 at: http://localhost:5000/#/experiments/480094317194489582/runs/b48cc24f5bb746e389fdfa9ceec481b7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:AUC: 0.8705\n",
      "INFO:__main__:LogLoss: 0.1641\n",
      "INFO:__main__:Accuracy: 0.9467\n",
      "INFO:__main__:Modelo guardado en: /Users/luis.caporal/Documents/Master - TEC/9. MLOps/MNA_MLOps_Equipo12_backup/notebooks/models/h2o_automl_best_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Entrenamiento completado con √©xito.\n",
      "Mejor modelo: StackedEnsemble_BestOfFamily_1_AutoML_1_20251112_191136\n",
      "üèÉ View run H2O_AutoML_Master_Run at: http://localhost:5000/#/experiments/480094317194489582/runs/b103db1002fb4f9da187142e131719ef\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/480094317194489582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.h2o\n",
    "import h2o\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURACI√ìN BASE\n",
    "# ==========================================================\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "target = \"target\"\n",
    "\n",
    "X = processed.drop(columns=[target])\n",
    "y = processed[target]\n",
    "\n",
    "df_train, df_test = train_test_split(processed, test_size=0.2, random_state=42, stratify=processed[target])\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURAR Y ENTRENAR H2O AutoML\n",
    "# ==========================================================\n",
    "with mlflow.start_run(run_name=\"H2O_AutoML_Master_Run\"):\n",
    "\n",
    "    trainer = H2OAutoMLTrainer(\n",
    "        max_models=20,\n",
    "        max_runtime_secs=300,\n",
    "        seed=42,\n",
    "        balance_classes=True,\n",
    "        stopping_metric=\"AUC\"\n",
    "    )\n",
    "\n",
    "    # Inicializar y preparar datos\n",
    "    trainer.prepare_data(df_train, target_col=target)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    trainer.train(target_col=target)\n",
    "\n",
    "    # ======================================================\n",
    "    # LOGS EN MLFLOW - PAR√ÅMETROS BASE\n",
    "    # ======================================================\n",
    "    summary = trainer.get_training_summary()\n",
    "    mlflow.log_params({\n",
    "        \"max_models\": summary[\"max_models\"],\n",
    "        \"max_runtime_secs\": summary[\"max_runtime_secs\"],\n",
    "        \"seed\": summary[\"seed\"],\n",
    "        \"balance_classes\": summary[\"balance_classes\"],\n",
    "        \"stopping_metric\": summary[\"stopping_metric\"],\n",
    "    })\n",
    "\n",
    "    # ======================================================\n",
    "    # LEADERBOARD COMPLETO\n",
    "    # ======================================================\n",
    "    leaderboard_df = trainer.get_leaderboard(as_dataframe=True)\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    leaderboard_path = \"./models/h2o_leaderboard.csv\"\n",
    "    leaderboard_df.to_csv(leaderboard_path, index=False)\n",
    "    mlflow.log_artifact(leaderboard_path)\n",
    "\n",
    "    logger.info(\"Registrando m√©tricas individuales de cada modelo del leaderboard...\")\n",
    "\n",
    "    # ======================================================\n",
    "    # REGISTRAR CADA MODELO INDIVIDUAL EN MLFLOW\n",
    "    # ======================================================\n",
    "\n",
    "    for idx, row in leaderboard_df.iterrows():\n",
    "        model_id = row[\"model_id\"]\n",
    "        model = h2o.get_model(model_id)\n",
    "\n",
    "        # Calcular performance del modelo sobre test set\n",
    "        test_h2o = h2o.H2OFrame(df_test)\n",
    "        performance = model.model_performance(test_h2o)\n",
    "\n",
    "        # ======== M√âTRICAS BASE ========\n",
    "        acc_list = performance.accuracy()\n",
    "        acc_value = acc_list[0][1] if isinstance(acc_list, list) and len(acc_list) > 0 else None\n",
    "        auc_value = performance.auc() if hasattr(performance, \"auc\") else None\n",
    "        logloss_value = performance.logloss() if hasattr(performance, \"logloss\") else None\n",
    "\n",
    "        # ======== PREDICCIONES PARA ROC ========\n",
    "        preds = model.predict(test_h2o).as_data_frame()\n",
    "        results_df = df_test.copy()\n",
    "        results_df[\"predicted_prob\"] = preds[\"p1\"].values\n",
    "        results_df[\"predicted_class\"] = preds[\"predict\"].values\n",
    "    \n",
    "        # ======== DETECTAR MODELO BASE ========\n",
    "        base_model = getattr(model, \"algo\", None)\n",
    "        if base_model is None:\n",
    "            if \"StackedEnsemble\" in model_id:\n",
    "                base_model = \"StackedEnsemble\"\n",
    "            else:\n",
    "                base_model = \"Unknown\"\n",
    "\n",
    "        # ======== MATRIZ DE CONFUSI√ìN ========\n",
    "        try:\n",
    "            cm = performance.confusion_matrix()\n",
    "            cm_df = cm.table.as_data_frame()\n",
    "            labels = cm_df.iloc[:2, 0].values\n",
    "            cm_values = cm_df.iloc[:2, 1:3].astype(int).values\n",
    "\n",
    "            # Extraer m√©tricas derivadas (binarias)\n",
    "            # Estructura de la matriz:\n",
    "            #  [[TN, FP],\n",
    "            #   [FN, TP]]\n",
    "            if cm_values.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm_values.flatten()\n",
    "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            else:\n",
    "                # Para problemas multiclase, usar promedio macro\n",
    "                precisions, recalls, f1s = [], [], []\n",
    "                for i in range(cm_values.shape[0]):\n",
    "                    tp = cm_values[i, i]\n",
    "                    fp = np.sum(cm_values[:, i]) - tp\n",
    "                    fn = np.sum(cm_values[i, :]) - tp\n",
    "                    precision_i = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                    recall_i = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                    f1_i = 2 * precision_i * recall_i / (precision_i + recall_i) if (precision_i + recall_i) > 0 else 0\n",
    "                    precisions.append(precision_i)\n",
    "                    recalls.append(recall_i)\n",
    "                    f1s.append(f1_i)\n",
    "                precision = np.mean(precisions)\n",
    "                recall = np.mean(recalls)\n",
    "                f1_score = np.mean(f1s)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"No se pudo obtener la matriz de confusi√≥n para {model_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # ======== SUB-RUN EN MLFLOW ========\n",
    "        with mlflow.start_run(run_name=f\"H2O_Model_{model_id}\", nested=True):\n",
    "            mlflow.log_params({\n",
    "                \"model_id\": model_id,\n",
    "                \"base_model\": base_model.capitalize()\n",
    "            })\n",
    "            mlflow.log_metrics({\n",
    "                \"AUC\": auc_value,\n",
    "                \"logloss\": logloss_value,\n",
    "                \"accuracy\": acc_value,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1_score\n",
    "            })\n",
    "            mlflow.log_param(\"model_name\", model_id)\n",
    "            logger.info(f\"‚úÖ Modelo {model_id} registrado: \")\n",
    "            mlflow.set_tag(\"model_name\", model_id)\n",
    "\n",
    "            # ======== GUARDAR MODELO ========\n",
    "            model_path = h2o.save_model(model=model, path=\"./models\", force=True)\n",
    "            mlflow.log_artifact(model_path)\n",
    "\n",
    "            # ======== MATRIZ DE CONFUSI√ìN COMO IMAGEN ========\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(cm_values, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=labels, yticklabels=labels)\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.title(f\"Confusion Matrix - {model_id}\")\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            os.makedirs(\"./visualization/confusion_matrices\", exist_ok=True)\n",
    "            cm_path = f\"./visualization/confusion_matrices/cm_{model_id}.png\"\n",
    "\n",
    "            plt.savefig(cm_path)\n",
    "            plt.close()\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                plot_interactive_roc(results_df[\"target\"], results_df[\"predicted_prob\"], model_name=model_id)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"No se pudo generar curva ROC para {model_id}: {e}\")\n",
    "\n",
    "            mlflow.log_artifact(cm_path)\n",
    "\n",
    "        logger.info(f\"‚úÖ Modelo {model_id} registrado: \")\n",
    "\n",
    "    # ======================================================\n",
    "    # REGISTRAR EL MODELO L√çDER FINAL\n",
    "    # ======================================================\n",
    "    leader_perf = trainer.get_model_performance(target_col=target)\n",
    "    # mlflow.h2o.log_model(trainer.leader, name=\"leader_model\")\n",
    "\n",
    "    save_path = trainer.save_model(model_name=\"h2o_automl_best_model\", base_path=\"./models\")\n",
    "\n",
    "    print(\"\\n‚úÖ Entrenamiento completado con √©xito.\")\n",
    "    print(f\"Mejor modelo: {trainer.leader.model_id}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
